{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49eb1bc-20a5-4b5b-99f4-f751996ad63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Enable memory efficient optimizations\n",
    "torch.backends.cudnn.benchmark = True\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "# Memory cleanup function\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Dataset class remains the same\n",
    "class FaultDetectionDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx, 0]\n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Memory optimized ResUNet\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, base_channels=32):  # Reduced base channels\n",
    "        super(ResUNet, self).__init__()\n",
    "        \n",
    "        # Encoder with reduced channels\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(3, base_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(base_channels, base_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(base_channels*2, base_channels*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*2, base_channels*4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(base_channels*4, base_channels*4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*6, base_channels*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(base_channels*2, base_channels*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels*2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels*3, base_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(base_channels, base_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(base_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Final layers\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 1, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder path with memory clearing\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(F.max_pool2d(e1, 2))\n",
    "        e3 = self.enc3(F.max_pool2d(e2, 2))\n",
    "        \n",
    "        # Decoder path\n",
    "        d3 = self.upsample(e3)\n",
    "        d3 = torch.cat([d3, e2], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        \n",
    "        d2 = self.upsample(d3)\n",
    "        d2 = torch.cat([d2, e1], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        \n",
    "        out = self.final(d2)\n",
    "        out = self.adaptive_pool(out)\n",
    "        return out.view(-1)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Clear memory every few batches\n",
    "            if batch_idx % 10 == 0:\n",
    "                clear_memory()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # Clear memory\n",
    "                clear_memory()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            report = classification_report(all_labels, all_preds, \n",
    "                                        target_names=['No Defect', 'Defect'])\n",
    "            print(f'\\nClassification Report:\\n{report}\\n')\n",
    "            \n",
    "        # Clear memory at the end of each epoch\n",
    "        clear_memory()\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ccab4-cbba-45cc-9a32-52b4d10a4c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n",
      "Train Loss: 0.5870, Train Acc: 0.6922\n",
      "Val Loss: 0.5228, Val Acc: 0.7292\n",
      "Epoch [2/20]\n",
      "Train Loss: 0.5324, Train Acc: 0.7289\n",
      "Val Loss: 0.4799, Val Acc: 0.7673\n",
      "Epoch [3/20]\n",
      "Train Loss: 0.4859, Train Acc: 0.7588\n",
      "Val Loss: 0.4751, Val Acc: 0.7496\n",
      "Epoch [4/20]\n",
      "Train Loss: 0.4640, Train Acc: 0.7709\n",
      "Val Loss: 0.3988, Val Acc: 0.8135\n",
      "Epoch [5/20]\n",
      "Train Loss: 0.4372, Train Acc: 0.7896\n",
      "Val Loss: 0.4592, Val Acc: 0.7554\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Defect       0.90      0.52      0.66      1178\n",
      "      Defect       0.71      0.95      0.81      1422\n",
      "\n",
      "    accuracy                           0.76      2600\n",
      "   macro avg       0.80      0.74      0.73      2600\n",
      "weighted avg       0.79      0.76      0.74      2600\n",
      "\n",
      "\n",
      "Epoch [6/20]\n",
      "Train Loss: 0.4120, Train Acc: 0.8028\n",
      "Val Loss: 0.4112, Val Acc: 0.8004\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "def main():\n",
    "    # Set smaller image size\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # Reduced image size\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    # Load and split data\n",
    "    df = pd.read_csv('defect_and_no_defect.csv')\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create datasets and dataloaders with smaller batch size\n",
    "    train_dataset = FaultDetectionDataset(train_df, \"train_images\", transform)\n",
    "    val_dataset = FaultDetectionDataset(val_df, \"train_images\", transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # Reduced batch size\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8)  # Reduced batch size\n",
    "    \n",
    "    # Model setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ResUNet(base_channels=32).to(device)  # Reduced base channels\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Clear memory before training\n",
    "    clear_memory()\n",
    "    \n",
    "    # Train model\n",
    "    metrics = train_model(model, train_loader, val_loader, criterion, \n",
    "                         optimizer, num_epochs=20, device=device)\n",
    "    \n",
    "    # Plot results\n",
    "    plot_metrics(*metrics)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), 'resunet_model.pth')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
